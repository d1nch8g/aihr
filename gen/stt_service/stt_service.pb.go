// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        v6.30.2
// source: proto/stt_service.proto

package stt_service

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	durationpb "google.golang.org/protobuf/types/known/durationpb"
	emptypb "google.golang.org/protobuf/types/known/emptypb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type RecognitionSpec_AudioEncoding int32

const (
	RecognitionSpec_AUDIO_ENCODING_UNSPECIFIED RecognitionSpec_AudioEncoding = 0
	// 16-bit signed little-endian (Linear PCM)
	RecognitionSpec_LINEAR16_PCM RecognitionSpec_AudioEncoding = 1
)

// Enum value maps for RecognitionSpec_AudioEncoding.
var (
	RecognitionSpec_AudioEncoding_name = map[int32]string{
		0: "AUDIO_ENCODING_UNSPECIFIED",
		1: "LINEAR16_PCM",
	}
	RecognitionSpec_AudioEncoding_value = map[string]int32{
		"AUDIO_ENCODING_UNSPECIFIED": 0,
		"LINEAR16_PCM":               1,
	}
)

func (x RecognitionSpec_AudioEncoding) Enum() *RecognitionSpec_AudioEncoding {
	p := new(RecognitionSpec_AudioEncoding)
	*p = x
	return p
}

func (x RecognitionSpec_AudioEncoding) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (RecognitionSpec_AudioEncoding) Descriptor() protoreflect.EnumDescriptor {
	return file_proto_stt_service_proto_enumTypes[0].Descriptor()
}

func (RecognitionSpec_AudioEncoding) Type() protoreflect.EnumType {
	return &file_proto_stt_service_proto_enumTypes[0]
}

func (x RecognitionSpec_AudioEncoding) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use RecognitionSpec_AudioEncoding.Descriptor instead.
func (RecognitionSpec_AudioEncoding) EnumDescriptor() ([]byte, []int) {
	return file_proto_stt_service_proto_rawDescGZIP(), []int{3, 0}
}

type StreamingRecognitionRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to StreamingRequest:
	//
	//	*StreamingRecognitionRequest_Config
	//	*StreamingRecognitionRequest_AudioContent
	StreamingRequest isStreamingRecognitionRequest_StreamingRequest `protobuf_oneof:"streaming_request"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *StreamingRecognitionRequest) Reset() {
	*x = StreamingRecognitionRequest{}
	mi := &file_proto_stt_service_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StreamingRecognitionRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamingRecognitionRequest) ProtoMessage() {}

func (x *StreamingRecognitionRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_stt_service_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamingRecognitionRequest.ProtoReflect.Descriptor instead.
func (*StreamingRecognitionRequest) Descriptor() ([]byte, []int) {
	return file_proto_stt_service_proto_rawDescGZIP(), []int{0}
}

func (x *StreamingRecognitionRequest) GetStreamingRequest() isStreamingRecognitionRequest_StreamingRequest {
	if x != nil {
		return x.StreamingRequest
	}
	return nil
}

func (x *StreamingRecognitionRequest) GetConfig() *RecognitionConfig {
	if x != nil {
		if x, ok := x.StreamingRequest.(*StreamingRecognitionRequest_Config); ok {
			return x.Config
		}
	}
	return nil
}

func (x *StreamingRecognitionRequest) GetAudioContent() []byte {
	if x != nil {
		if x, ok := x.StreamingRequest.(*StreamingRecognitionRequest_AudioContent); ok {
			return x.AudioContent
		}
	}
	return nil
}

type isStreamingRecognitionRequest_StreamingRequest interface {
	isStreamingRecognitionRequest_StreamingRequest()
}

type StreamingRecognitionRequest_Config struct {
	Config *RecognitionConfig `protobuf:"bytes,1,opt,name=config,proto3,oneof"`
}

type StreamingRecognitionRequest_AudioContent struct {
	AudioContent []byte `protobuf:"bytes,2,opt,name=audio_content,json=audioContent,proto3,oneof"`
}

func (*StreamingRecognitionRequest_Config) isStreamingRecognitionRequest_StreamingRequest() {}

func (*StreamingRecognitionRequest_AudioContent) isStreamingRecognitionRequest_StreamingRequest() {}

type StreamingRecognitionResponse struct {
	state         protoimpl.MessageState    `protogen:"open.v1"`
	Chunks        []*SpeechRecognitionChunk `protobuf:"bytes,1,rep,name=chunks,proto3" json:"chunks,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StreamingRecognitionResponse) Reset() {
	*x = StreamingRecognitionResponse{}
	mi := &file_proto_stt_service_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StreamingRecognitionResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamingRecognitionResponse) ProtoMessage() {}

func (x *StreamingRecognitionResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_stt_service_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamingRecognitionResponse.ProtoReflect.Descriptor instead.
func (*StreamingRecognitionResponse) Descriptor() ([]byte, []int) {
	return file_proto_stt_service_proto_rawDescGZIP(), []int{1}
}

func (x *StreamingRecognitionResponse) GetChunks() []*SpeechRecognitionChunk {
	if x != nil {
		return x.Chunks
	}
	return nil
}

type RecognitionConfig struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Specification *RecognitionSpec       `protobuf:"bytes,1,opt,name=specification,proto3" json:"specification,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RecognitionConfig) Reset() {
	*x = RecognitionConfig{}
	mi := &file_proto_stt_service_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RecognitionConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionConfig) ProtoMessage() {}

func (x *RecognitionConfig) ProtoReflect() protoreflect.Message {
	mi := &file_proto_stt_service_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionConfig.ProtoReflect.Descriptor instead.
func (*RecognitionConfig) Descriptor() ([]byte, []int) {
	return file_proto_stt_service_proto_rawDescGZIP(), []int{2}
}

func (x *RecognitionConfig) GetSpecification() *RecognitionSpec {
	if x != nil {
		return x.Specification
	}
	return nil
}

type RecognitionSpec struct {
	state         protoimpl.MessageState        `protogen:"open.v1"`
	AudioEncoding RecognitionSpec_AudioEncoding `protobuf:"varint,1,opt,name=audio_encoding,json=audioEncoding,proto3,enum=vosk.stt.v1.RecognitionSpec_AudioEncoding" json:"audio_encoding,omitempty"`
	// 8000, 16000, 48000 only for pcm
	SampleRateHertz int64 `protobuf:"varint,2,opt,name=sample_rate_hertz,json=sampleRateHertz,proto3" json:"sample_rate_hertz,omitempty"`
	// code in BCP-47
	LanguageCode    string `protobuf:"bytes,3,opt,name=language_code,json=languageCode,proto3" json:"language_code,omitempty"`
	ProfanityFilter bool   `protobuf:"varint,4,opt,name=profanity_filter,json=profanityFilter,proto3" json:"profanity_filter,omitempty"`
	Model           string `protobuf:"bytes,5,opt,name=model,proto3" json:"model,omitempty"`
	// If set true, tentative hypotheses may be returned as they become available (final=false flag)
	// If false or omitted, only final=true result(s) are returned.
	// Makes sense only for StreamingRecognize requests.
	PartialResults  bool `protobuf:"varint,7,opt,name=partial_results,json=partialResults,proto3" json:"partial_results,omitempty"`
	SingleUtterance bool `protobuf:"varint,8,opt,name=single_utterance,json=singleUtterance,proto3" json:"single_utterance,omitempty"`
	// This mark allows disable normalization text
	RawResults bool `protobuf:"varint,10,opt,name=raw_results,json=rawResults,proto3" json:"raw_results,omitempty"`
	// Maximum number of recognition hypotheses to be returned.
	// Specifically, the maximum number of `SpeechRecognitionAlternative` messages
	// within each `SpeechRecognitionResult`.
	// The server may return fewer than `max_alternatives`.
	// Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
	// one. If omitted, will return a maximum of one.
	MaxAlternatives int32 `protobuf:"varint,11,opt,name=max_alternatives,json=maxAlternatives,proto3" json:"max_alternatives,omitempty"`
	// If `true`, the top result includes a list of words and
	// the start and end time offsets (timestamps) for those words. If
	// `false`, no word-level time offset information is returned. The default is
	// `false`.
	EnableWordTimeOffsets bool `protobuf:"varint,12,opt,name=enable_word_time_offsets,json=enableWordTimeOffsets,proto3" json:"enable_word_time_offsets,omitempty"`
	unknownFields         protoimpl.UnknownFields
	sizeCache             protoimpl.SizeCache
}

func (x *RecognitionSpec) Reset() {
	*x = RecognitionSpec{}
	mi := &file_proto_stt_service_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RecognitionSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionSpec) ProtoMessage() {}

func (x *RecognitionSpec) ProtoReflect() protoreflect.Message {
	mi := &file_proto_stt_service_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionSpec.ProtoReflect.Descriptor instead.
func (*RecognitionSpec) Descriptor() ([]byte, []int) {
	return file_proto_stt_service_proto_rawDescGZIP(), []int{3}
}

func (x *RecognitionSpec) GetAudioEncoding() RecognitionSpec_AudioEncoding {
	if x != nil {
		return x.AudioEncoding
	}
	return RecognitionSpec_AUDIO_ENCODING_UNSPECIFIED
}

func (x *RecognitionSpec) GetSampleRateHertz() int64 {
	if x != nil {
		return x.SampleRateHertz
	}
	return 0
}

func (x *RecognitionSpec) GetLanguageCode() string {
	if x != nil {
		return x.LanguageCode
	}
	return ""
}

func (x *RecognitionSpec) GetProfanityFilter() bool {
	if x != nil {
		return x.ProfanityFilter
	}
	return false
}

func (x *RecognitionSpec) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *RecognitionSpec) GetPartialResults() bool {
	if x != nil {
		return x.PartialResults
	}
	return false
}

func (x *RecognitionSpec) GetSingleUtterance() bool {
	if x != nil {
		return x.SingleUtterance
	}
	return false
}

func (x *RecognitionSpec) GetRawResults() bool {
	if x != nil {
		return x.RawResults
	}
	return false
}

func (x *RecognitionSpec) GetMaxAlternatives() int32 {
	if x != nil {
		return x.MaxAlternatives
	}
	return 0
}

func (x *RecognitionSpec) GetEnableWordTimeOffsets() bool {
	if x != nil {
		return x.EnableWordTimeOffsets
	}
	return false
}

type SpeechRecognitionChunk struct {
	state        protoimpl.MessageState          `protogen:"open.v1"`
	Alternatives []*SpeechRecognitionAlternative `protobuf:"bytes,1,rep,name=alternatives,proto3" json:"alternatives,omitempty"`
	// This flag shows that the received chunk contains a part of the recognized text that won't be changed.
	Final bool `protobuf:"varint,2,opt,name=final,proto3" json:"final,omitempty"`
	// This flag shows that the received chunk is the end of an utterance.
	EndOfUtterance bool `protobuf:"varint,3,opt,name=end_of_utterance,json=endOfUtterance,proto3" json:"end_of_utterance,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *SpeechRecognitionChunk) Reset() {
	*x = SpeechRecognitionChunk{}
	mi := &file_proto_stt_service_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechRecognitionChunk) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechRecognitionChunk) ProtoMessage() {}

func (x *SpeechRecognitionChunk) ProtoReflect() protoreflect.Message {
	mi := &file_proto_stt_service_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SpeechRecognitionChunk.ProtoReflect.Descriptor instead.
func (*SpeechRecognitionChunk) Descriptor() ([]byte, []int) {
	return file_proto_stt_service_proto_rawDescGZIP(), []int{4}
}

func (x *SpeechRecognitionChunk) GetAlternatives() []*SpeechRecognitionAlternative {
	if x != nil {
		return x.Alternatives
	}
	return nil
}

func (x *SpeechRecognitionChunk) GetFinal() bool {
	if x != nil {
		return x.Final
	}
	return false
}

func (x *SpeechRecognitionChunk) GetEndOfUtterance() bool {
	if x != nil {
		return x.EndOfUtterance
	}
	return false
}

type SpeechRecognitionAlternative struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Text          string                 `protobuf:"bytes,1,opt,name=text,proto3" json:"text,omitempty"`
	Confidence    float32                `protobuf:"fixed32,2,opt,name=confidence,proto3" json:"confidence,omitempty"`
	Words         []*WordInfo            `protobuf:"bytes,3,rep,name=words,proto3" json:"words,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SpeechRecognitionAlternative) Reset() {
	*x = SpeechRecognitionAlternative{}
	mi := &file_proto_stt_service_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechRecognitionAlternative) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechRecognitionAlternative) ProtoMessage() {}

func (x *SpeechRecognitionAlternative) ProtoReflect() protoreflect.Message {
	mi := &file_proto_stt_service_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SpeechRecognitionAlternative.ProtoReflect.Descriptor instead.
func (*SpeechRecognitionAlternative) Descriptor() ([]byte, []int) {
	return file_proto_stt_service_proto_rawDescGZIP(), []int{5}
}

func (x *SpeechRecognitionAlternative) GetText() string {
	if x != nil {
		return x.Text
	}
	return ""
}

func (x *SpeechRecognitionAlternative) GetConfidence() float32 {
	if x != nil {
		return x.Confidence
	}
	return 0
}

func (x *SpeechRecognitionAlternative) GetWords() []*WordInfo {
	if x != nil {
		return x.Words
	}
	return nil
}

type WordInfo struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	StartTime     *durationpb.Duration   `protobuf:"bytes,1,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"`
	EndTime       *durationpb.Duration   `protobuf:"bytes,2,opt,name=end_time,json=endTime,proto3" json:"end_time,omitempty"`
	Word          string                 `protobuf:"bytes,3,opt,name=word,proto3" json:"word,omitempty"`
	Confidence    float32                `protobuf:"fixed32,4,opt,name=confidence,proto3" json:"confidence,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *WordInfo) Reset() {
	*x = WordInfo{}
	mi := &file_proto_stt_service_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *WordInfo) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*WordInfo) ProtoMessage() {}

func (x *WordInfo) ProtoReflect() protoreflect.Message {
	mi := &file_proto_stt_service_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use WordInfo.ProtoReflect.Descriptor instead.
func (*WordInfo) Descriptor() ([]byte, []int) {
	return file_proto_stt_service_proto_rawDescGZIP(), []int{6}
}

func (x *WordInfo) GetStartTime() *durationpb.Duration {
	if x != nil {
		return x.StartTime
	}
	return nil
}

func (x *WordInfo) GetEndTime() *durationpb.Duration {
	if x != nil {
		return x.EndTime
	}
	return nil
}

func (x *WordInfo) GetWord() string {
	if x != nil {
		return x.Word
	}
	return ""
}

func (x *WordInfo) GetConfidence() float32 {
	if x != nil {
		return x.Confidence
	}
	return 0
}

type StatsResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	NStreams      int32                  `protobuf:"varint,1,opt,name=n_streams,json=nStreams,proto3" json:"n_streams,omitempty"`
	NTotalStreams int32                  `protobuf:"varint,2,opt,name=n_total_streams,json=nTotalStreams,proto3" json:"n_total_streams,omitempty"`
	MaxChunkRtf   float32                `protobuf:"fixed32,4,opt,name=max_chunk_rtf,json=maxChunkRtf,proto3" json:"max_chunk_rtf,omitempty"`
	MaxStreamRtf  float32                `protobuf:"fixed32,6,opt,name=max_stream_rtf,json=maxStreamRtf,proto3" json:"max_stream_rtf,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StatsResponse) Reset() {
	*x = StatsResponse{}
	mi := &file_proto_stt_service_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StatsResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StatsResponse) ProtoMessage() {}

func (x *StatsResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_stt_service_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StatsResponse.ProtoReflect.Descriptor instead.
func (*StatsResponse) Descriptor() ([]byte, []int) {
	return file_proto_stt_service_proto_rawDescGZIP(), []int{7}
}

func (x *StatsResponse) GetNStreams() int32 {
	if x != nil {
		return x.NStreams
	}
	return 0
}

func (x *StatsResponse) GetNTotalStreams() int32 {
	if x != nil {
		return x.NTotalStreams
	}
	return 0
}

func (x *StatsResponse) GetMaxChunkRtf() float32 {
	if x != nil {
		return x.MaxChunkRtf
	}
	return 0
}

func (x *StatsResponse) GetMaxStreamRtf() float32 {
	if x != nil {
		return x.MaxStreamRtf
	}
	return 0
}

var File_proto_stt_service_proto protoreflect.FileDescriptor

const file_proto_stt_service_proto_rawDesc = "" +
	"\n" +
	"\x17proto/stt_service.proto\x12\vvosk.stt.v1\x1a\x1egoogle/protobuf/duration.proto\x1a\x1bgoogle/protobuf/empty.proto\"\x93\x01\n" +
	"\x1bStreamingRecognitionRequest\x128\n" +
	"\x06config\x18\x01 \x01(\v2\x1e.vosk.stt.v1.RecognitionConfigH\x00R\x06config\x12%\n" +
	"\raudio_content\x18\x02 \x01(\fH\x00R\faudioContentB\x13\n" +
	"\x11streaming_request\"z\n" +
	"\x1cStreamingRecognitionResponse\x12;\n" +
	"\x06chunks\x18\x01 \x03(\v2#.vosk.stt.v1.SpeechRecognitionChunkR\x06chunksJ\x04\b\x02\x10\x03R\x17end_of_single_utterance\"W\n" +
	"\x11RecognitionConfig\x12B\n" +
	"\rspecification\x18\x01 \x01(\v2\x1c.vosk.stt.v1.RecognitionSpecR\rspecification\"\x92\x04\n" +
	"\x0fRecognitionSpec\x12Q\n" +
	"\x0eaudio_encoding\x18\x01 \x01(\x0e2*.vosk.stt.v1.RecognitionSpec.AudioEncodingR\raudioEncoding\x12*\n" +
	"\x11sample_rate_hertz\x18\x02 \x01(\x03R\x0fsampleRateHertz\x12#\n" +
	"\rlanguage_code\x18\x03 \x01(\tR\flanguageCode\x12)\n" +
	"\x10profanity_filter\x18\x04 \x01(\bR\x0fprofanityFilter\x12\x14\n" +
	"\x05model\x18\x05 \x01(\tR\x05model\x12'\n" +
	"\x0fpartial_results\x18\a \x01(\bR\x0epartialResults\x12)\n" +
	"\x10single_utterance\x18\b \x01(\bR\x0fsingleUtterance\x12\x1f\n" +
	"\vraw_results\x18\n" +
	" \x01(\bR\n" +
	"rawResults\x12)\n" +
	"\x10max_alternatives\x18\v \x01(\x05R\x0fmaxAlternatives\x127\n" +
	"\x18enable_word_time_offsets\x18\f \x01(\bR\x15enableWordTimeOffsets\"A\n" +
	"\rAudioEncoding\x12\x1e\n" +
	"\x1aAUDIO_ENCODING_UNSPECIFIED\x10\x00\x12\x10\n" +
	"\fLINEAR16_PCM\x10\x01\"\xa7\x01\n" +
	"\x16SpeechRecognitionChunk\x12M\n" +
	"\falternatives\x18\x01 \x03(\v2).vosk.stt.v1.SpeechRecognitionAlternativeR\falternatives\x12\x14\n" +
	"\x05final\x18\x02 \x01(\bR\x05final\x12(\n" +
	"\x10end_of_utterance\x18\x03 \x01(\bR\x0eendOfUtterance\"\x7f\n" +
	"\x1cSpeechRecognitionAlternative\x12\x12\n" +
	"\x04text\x18\x01 \x01(\tR\x04text\x12\x1e\n" +
	"\n" +
	"confidence\x18\x02 \x01(\x02R\n" +
	"confidence\x12+\n" +
	"\x05words\x18\x03 \x03(\v2\x15.vosk.stt.v1.WordInfoR\x05words\"\xae\x01\n" +
	"\bWordInfo\x128\n" +
	"\n" +
	"start_time\x18\x01 \x01(\v2\x19.google.protobuf.DurationR\tstartTime\x124\n" +
	"\bend_time\x18\x02 \x01(\v2\x19.google.protobuf.DurationR\aendTime\x12\x12\n" +
	"\x04word\x18\x03 \x01(\tR\x04word\x12\x1e\n" +
	"\n" +
	"confidence\x18\x04 \x01(\x02R\n" +
	"confidence\"\x9e\x01\n" +
	"\rStatsResponse\x12\x1b\n" +
	"\tn_streams\x18\x01 \x01(\x05R\bnStreams\x12&\n" +
	"\x0fn_total_streams\x18\x02 \x01(\x05R\rnTotalStreams\x12\"\n" +
	"\rmax_chunk_rtf\x18\x04 \x01(\x02R\vmaxChunkRtf\x12$\n" +
	"\x0emax_stream_rtf\x18\x06 \x01(\x02R\fmaxStreamRtf2}\n" +
	"\n" +
	"SttService\x12o\n" +
	"\x12StreamingRecognize\x12(.vosk.stt.v1.StreamingRecognitionRequest\x1a).vosk.stt.v1.StreamingRecognitionResponse\"\x00(\x010\x012P\n" +
	"\fStatsService\x12@\n" +
	"\bGetStats\x12\x16.google.protobuf.Empty\x1a\x1a.vosk.stt.v1.StatsResponse\"\x00B)Z'github.com/d1nch8g/aihr/gen/stt_serviceb\x06proto3"

var (
	file_proto_stt_service_proto_rawDescOnce sync.Once
	file_proto_stt_service_proto_rawDescData []byte
)

func file_proto_stt_service_proto_rawDescGZIP() []byte {
	file_proto_stt_service_proto_rawDescOnce.Do(func() {
		file_proto_stt_service_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_proto_stt_service_proto_rawDesc), len(file_proto_stt_service_proto_rawDesc)))
	})
	return file_proto_stt_service_proto_rawDescData
}

var file_proto_stt_service_proto_enumTypes = make([]protoimpl.EnumInfo, 1)
var file_proto_stt_service_proto_msgTypes = make([]protoimpl.MessageInfo, 8)
var file_proto_stt_service_proto_goTypes = []any{
	(RecognitionSpec_AudioEncoding)(0),   // 0: vosk.stt.v1.RecognitionSpec.AudioEncoding
	(*StreamingRecognitionRequest)(nil),  // 1: vosk.stt.v1.StreamingRecognitionRequest
	(*StreamingRecognitionResponse)(nil), // 2: vosk.stt.v1.StreamingRecognitionResponse
	(*RecognitionConfig)(nil),            // 3: vosk.stt.v1.RecognitionConfig
	(*RecognitionSpec)(nil),              // 4: vosk.stt.v1.RecognitionSpec
	(*SpeechRecognitionChunk)(nil),       // 5: vosk.stt.v1.SpeechRecognitionChunk
	(*SpeechRecognitionAlternative)(nil), // 6: vosk.stt.v1.SpeechRecognitionAlternative
	(*WordInfo)(nil),                     // 7: vosk.stt.v1.WordInfo
	(*StatsResponse)(nil),                // 8: vosk.stt.v1.StatsResponse
	(*durationpb.Duration)(nil),          // 9: google.protobuf.Duration
	(*emptypb.Empty)(nil),                // 10: google.protobuf.Empty
}
var file_proto_stt_service_proto_depIdxs = []int32{
	3,  // 0: vosk.stt.v1.StreamingRecognitionRequest.config:type_name -> vosk.stt.v1.RecognitionConfig
	5,  // 1: vosk.stt.v1.StreamingRecognitionResponse.chunks:type_name -> vosk.stt.v1.SpeechRecognitionChunk
	4,  // 2: vosk.stt.v1.RecognitionConfig.specification:type_name -> vosk.stt.v1.RecognitionSpec
	0,  // 3: vosk.stt.v1.RecognitionSpec.audio_encoding:type_name -> vosk.stt.v1.RecognitionSpec.AudioEncoding
	6,  // 4: vosk.stt.v1.SpeechRecognitionChunk.alternatives:type_name -> vosk.stt.v1.SpeechRecognitionAlternative
	7,  // 5: vosk.stt.v1.SpeechRecognitionAlternative.words:type_name -> vosk.stt.v1.WordInfo
	9,  // 6: vosk.stt.v1.WordInfo.start_time:type_name -> google.protobuf.Duration
	9,  // 7: vosk.stt.v1.WordInfo.end_time:type_name -> google.protobuf.Duration
	1,  // 8: vosk.stt.v1.SttService.StreamingRecognize:input_type -> vosk.stt.v1.StreamingRecognitionRequest
	10, // 9: vosk.stt.v1.StatsService.GetStats:input_type -> google.protobuf.Empty
	2,  // 10: vosk.stt.v1.SttService.StreamingRecognize:output_type -> vosk.stt.v1.StreamingRecognitionResponse
	8,  // 11: vosk.stt.v1.StatsService.GetStats:output_type -> vosk.stt.v1.StatsResponse
	10, // [10:12] is the sub-list for method output_type
	8,  // [8:10] is the sub-list for method input_type
	8,  // [8:8] is the sub-list for extension type_name
	8,  // [8:8] is the sub-list for extension extendee
	0,  // [0:8] is the sub-list for field type_name
}

func init() { file_proto_stt_service_proto_init() }
func file_proto_stt_service_proto_init() {
	if File_proto_stt_service_proto != nil {
		return
	}
	file_proto_stt_service_proto_msgTypes[0].OneofWrappers = []any{
		(*StreamingRecognitionRequest_Config)(nil),
		(*StreamingRecognitionRequest_AudioContent)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_proto_stt_service_proto_rawDesc), len(file_proto_stt_service_proto_rawDesc)),
			NumEnums:      1,
			NumMessages:   8,
			NumExtensions: 0,
			NumServices:   2,
		},
		GoTypes:           file_proto_stt_service_proto_goTypes,
		DependencyIndexes: file_proto_stt_service_proto_depIdxs,
		EnumInfos:         file_proto_stt_service_proto_enumTypes,
		MessageInfos:      file_proto_stt_service_proto_msgTypes,
	}.Build()
	File_proto_stt_service_proto = out.File
	file_proto_stt_service_proto_goTypes = nil
	file_proto_stt_service_proto_depIdxs = nil
}
